{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dd4e82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support as sk\n",
    "from sklearn.metrics import f1_score ## F1 Score 구하기\n",
    "from sklearn.metrics import accuracy_score\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "070df1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA=torch.cuda.is_available()\n",
    "DEVICE=torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea13541b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch과 Batch_size 선언\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "535883df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('../optimal_data2/'+'Continous_2weeks_2day_1term.xlsx')\n",
    "df.head()\n",
    "X=df.iloc[:,[1,3,4,5,6,7]]\n",
    "y=df.iloc[:,-1]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X=pd.DataFrame(X)\n",
    "\n",
    "#결과 넣을 배열\n",
    "Result=[[0 for j in range(4)] for i in range(10)]\n",
    "Count=int(322/10)*83\n",
    "pred_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dd7fa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        self.input_layer = nn.Linear(6, 128)\n",
    "        self.hidden_layer1 = nn.Linear(128, 256)\n",
    "        self.hidden_layer2 = nn.Linear(256, 128)\n",
    "        self.output_layer   = nn.Linear(128,3)\n",
    "        \n",
    "        # Define proportion or neurons to dropout\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out =  F.relu(self.input_layer(x))\n",
    "        out =  F.relu(self.hidden_layer1(out))\n",
    "        out= self.dropout(out)\n",
    "        out =  F.relu(self.hidden_layer2(out))\n",
    "        out= self.dropout(out)\n",
    "        out =  F.relu(self.output_layer(out))\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4140eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=DNN().to(DEVICE)\n",
    "# # 옵티마이저를 정의합니다. 옵티마이저에는 model.parameters()를 지정해야 합니다.\n",
    "# optimizer    = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# # 손실함수(loss function)을 지정합니다. Multi-Class Classification 이기 때문에 CrossEntropy 손실을 지정하였습니다.\n",
    "# loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7e3d79",
   "metadata": {},
   "source": [
    "### 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3f2c383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # 학습 데이터를 DEVICE의 메모리로 보냄\n",
    "        data, target=data.to(DEVICE), target.to(DEVICE)\n",
    "        #매 반복(iteration) 마다 기울기를 계산하기 위해 zero_grad() 호출\n",
    "        optimizer.zero_grad()\n",
    "        # 실제 모델의 예측값(output) 받아오기\n",
    "        output=model(data)\n",
    "        #정답 데이터와의 CrossEntropyLoss 계산\n",
    "        # 손실함수에 output, label 값을 대입하여 손실을 계산합니다.\n",
    "        loss = F.cross_entropy(output,target)\n",
    "        #기울기 계산\n",
    "        loss.backward()\n",
    "        # 계산된 Gradient를 업데이트 합니다.\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae2cd05",
   "metadata": {},
   "source": [
    "### 테스트 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad328140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    # 모델을 평가 모드로 전환\n",
    "    model.eval()\n",
    "    # 필요한 변수 초기화\n",
    "    # Test과정에서의 Loss = test_loss\n",
    "    # 실제 모델의 예측이 정답과 맞은 횟수 = correct\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    pred_list=[]\n",
    "    pred_array=[]\n",
    "    with torch.no_grad(): # 평가 과정에서는 기울기를 계산하지 않으므로, no_grad명시\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(data)\n",
    "            \n",
    "            _, pred = output.max(dim=1)\n",
    "            pred_array=pred.tolist()\n",
    "            pred_list+=pred_array\n",
    "                                    # confusion matrix를 위해 pred 리턴 값\n",
    "           \n",
    "            # 모든 오차 더하기\n",
    "            test_loss +=  F.cross_entropy(output, target, reduction=\"sum\").item()\n",
    "            \n",
    "            # 가장 큰 값을 가진 클래스가 모델의 예측입니다.\n",
    "            # 예측 클래스(pred)과 정답 클래스를 비교하여 일치할 경우 correct에 1을 더합니다.\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            # eq() 함수는 값이 일치하면 1을, 아니면 0을 출력.\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    #정확도 계산\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy, pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51ae5652",
   "metadata": {},
   "outputs": [],
   "source": [
    "#한 사람당 데이터 수\n",
    "Count_1=int(83*0.1)\n",
    "#한 사람당 데이터 수\n",
    "Count_2=83\n",
    "\n",
    "X_test=pd.DataFrame()\n",
    "X_train=pd.DataFrame()\n",
    "y_test=pd.DataFrame()\n",
    "y_train=pd.DataFrame()\n",
    "empty=pd.DataFrame()\n",
    "\n",
    "#결과 넣을 배열\n",
    "Result=[[0 for j in range(4)] for i in range(10)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13525793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE 적용 전 Train 레이블 값 분포: \n",
      " 0.0    22300\n",
      "1.0     1194\n",
      "2.0      656\n",
      "dtype: int64\n",
      "SMOTE 적용 전 Test 레이블 값 분포: \n",
      " 0.0    2290\n",
      "1.0     161\n",
      "2.0     125\n",
      "dtype: int64\n",
      "SMOTE 적용 후 학습용 피처/레이블 데이터 세트:  (2576, 6) (2576, 1)\n",
      "SMOTE 적용 후 Train 레이블 값 분포: \n",
      " 0.0    22300\n",
      "1.0    22300\n",
      "2.0    22300\n",
      "dtype: int64\n",
      "SMOTE 적용 후 Test 레이블 값 분포: \n",
      " 0.0    2290\n",
      "1.0     161\n",
      "2.0     125\n",
      "dtype: int64\n",
      "X_test 2576\n",
      "y_test tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "[1] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[2] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[3] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[4] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[5] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[6] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[7] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[8] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[9] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[10] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[11] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[12] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[13] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[14] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[15] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[16] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[17] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[18] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[19] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[20] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[21] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[22] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[23] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[24] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[25] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[26] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[27] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[28] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[29] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[30] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[31] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[32] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[33] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[34] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[35] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[36] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[37] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[38] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[39] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[40] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[41] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[42] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[43] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[44] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[45] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[46] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[47] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[48] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[49] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[50] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[51] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[52] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[53] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[54] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[55] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[56] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[57] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[58] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[59] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[60] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[61] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[62] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[63] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[64] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[65] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[66] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[67] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[68] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[69] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[70] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[71] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[72] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[73] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[74] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[75] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[76] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[77] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[78] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[79] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[80] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[81] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[82] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[83] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[84] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[85] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[86] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[87] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[88] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[89] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[90] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[91] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[92] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[93] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[94] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[95] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[96] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[97] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[98] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[99] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[100] Test Loss: 1.0986, Accuracy: 88.90%\n",
      "[0]Accuracy : 88.8975155279503\n",
      "[0]F1score : 0.8367254852404695\n",
      "[0]Precision : 0.7902768267042167\n",
      "[0]Recall : 0.8889751552795031\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaemin\\Anaconda3\\envs\\py38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE 적용 전 Train 레이블 값 분포: \n",
      " 0.0    22300\n",
      "1.0     1194\n",
      "2.0      656\n",
      "dtype: int64\n",
      "SMOTE 적용 전 Test 레이블 값 분포: \n",
      " 0.0    2371\n",
      "1.0     145\n",
      "2.0      60\n",
      "dtype: int64\n",
      "SMOTE 적용 후 학습용 피처/레이블 데이터 세트:  (2576, 6) (2576, 1)\n",
      "SMOTE 적용 후 Train 레이블 값 분포: \n",
      " 0.0    22300\n",
      "1.0    22300\n",
      "2.0    22300\n",
      "dtype: int64\n",
      "SMOTE 적용 후 Test 레이블 값 분포: \n",
      " 0.0    2371\n",
      "1.0     145\n",
      "2.0      60\n",
      "dtype: int64\n",
      "X_test 2576\n",
      "y_test tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "[1] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[2] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[3] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[4] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[5] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[6] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[7] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[8] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[9] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[10] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[11] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[12] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[13] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[14] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[15] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[16] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[17] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[18] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[19] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[20] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[21] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[22] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[23] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[24] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[25] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[26] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[27] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[28] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[29] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[30] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[31] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[32] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[33] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[34] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[35] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[36] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[37] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[38] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[39] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[40] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[41] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[42] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[43] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[44] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[45] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[46] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[47] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[48] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[49] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[50] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[51] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[52] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[53] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[54] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[55] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[56] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[57] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[58] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[59] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[60] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[61] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[62] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[63] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[64] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[65] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[66] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[67] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[68] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[69] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[70] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[71] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[72] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[73] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[74] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[75] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[76] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[77] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[78] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[79] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[80] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[81] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[82] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[83] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[84] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[85] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[86] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[87] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[88] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[89] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[90] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[91] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[92] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[93] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[94] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[95] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[96] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[97] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[98] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[99] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[100] Test Loss: 1.0986, Accuracy: 92.04%\n",
      "[1]Accuracy : 92.04192546583852\n",
      "[1]F1score : 0.8822777654315872\n",
      "[1]Precision : 0.8471716043458972\n",
      "[1]Recall : 0.9204192546583851\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaemin\\Anaconda3\\envs\\py38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE 적용 전 Train 레이블 값 분포: \n",
      " 0.0    22300\n",
      "1.0     1194\n",
      "2.0      656\n",
      "dtype: int64\n",
      "SMOTE 적용 전 Test 레이블 값 분포: \n",
      " 0.0    2295\n",
      "1.0     165\n",
      "2.0     116\n",
      "dtype: int64\n",
      "SMOTE 적용 후 학습용 피처/레이블 데이터 세트:  (2576, 6) (2576, 1)\n",
      "SMOTE 적용 후 Train 레이블 값 분포: \n",
      " 0.0    22300\n",
      "1.0    22300\n",
      "2.0    22300\n",
      "dtype: int64\n",
      "SMOTE 적용 후 Test 레이블 값 분포: \n",
      " 0.0    2295\n",
      "1.0     165\n",
      "2.0     116\n",
      "dtype: int64\n",
      "X_test 2576\n",
      "y_test tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "[1] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[2] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[3] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[4] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[5] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[6] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[7] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[8] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[9] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[10] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[11] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[12] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[13] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[14] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[15] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[16] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[17] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[18] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[19] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[20] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[21] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[22] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[23] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[24] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[25] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[26] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[27] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[28] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[29] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[30] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[31] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[32] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[33] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[34] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[35] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[36] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[37] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[38] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[39] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[40] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[41] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[42] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[43] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[44] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[45] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[46] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[47] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[48] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[49] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[50] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[51] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[52] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[53] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[54] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[55] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[56] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[57] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[58] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[59] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[60] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[61] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[62] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[63] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[64] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[65] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[66] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[67] Test Loss: 1.0986, Accuracy: 89.05%\n",
      "[68] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[69] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[70] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[71] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[72] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[73] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[74] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[75] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[76] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[77] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[78] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[79] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[80] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[81] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[82] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[83] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[84] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[85] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[86] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[87] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[88] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[89] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[90] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[91] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[92] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[93] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[94] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[95] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[96] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[97] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[98] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[99] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[100] Test Loss: 1.0986, Accuracy: 89.09%\n",
      "[2]Accuracy : 89.09161490683229\n",
      "[2]F1score : 0.8395206578163832\n",
      "[2]Precision : 0.7937315846707302\n",
      "[2]Recall : 0.890916149068323\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaemin\\Anaconda3\\envs\\py38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE 적용 전 Train 레이블 값 분포: \n",
      " 0.0    22300\n",
      "1.0     1194\n",
      "2.0      656\n",
      "dtype: int64\n",
      "SMOTE 적용 전 Test 레이블 값 분포: \n",
      " 0.0    2327\n",
      "1.0     147\n",
      "2.0     102\n",
      "dtype: int64\n",
      "SMOTE 적용 후 학습용 피처/레이블 데이터 세트:  (2576, 6) (2576, 1)\n",
      "SMOTE 적용 후 Train 레이블 값 분포: \n",
      " 0.0    22300\n",
      "1.0    22300\n",
      "2.0    22300\n",
      "dtype: int64\n",
      "SMOTE 적용 후 Test 레이블 값 분포: \n",
      " 0.0    2327\n",
      "1.0     147\n",
      "2.0     102\n",
      "dtype: int64\n",
      "X_test 2576\n",
      "y_test tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "[1] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[2] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[3] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[4] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[5] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[6] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[7] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[8] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[9] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[10] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[11] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[12] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[13] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[14] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[15] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[16] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[17] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[18] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[19] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[20] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[21] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[22] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[23] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[24] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[25] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[26] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[27] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[28] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[29] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[30] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[31] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[32] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[33] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[34] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[35] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[36] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[37] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[38] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[39] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[40] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[41] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[42] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[43] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[44] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[45] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[46] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[47] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[48] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[49] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[50] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[51] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[52] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[53] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[54] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[55] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[56] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[57] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[58] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[59] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[60] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[61] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[62] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[63] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[64] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[65] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[66] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[67] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[68] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[69] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[70] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[71] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[72] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[73] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[74] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[75] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[76] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[77] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[78] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[79] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[80] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[81] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[82] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[83] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[84] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[85] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[86] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[87] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[88] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[89] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[90] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[91] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[92] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[93] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[94] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[95] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[96] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[97] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[98] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[99] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[100] Test Loss: 1.0986, Accuracy: 90.33%\n",
      "[3]Accuracy : 90.33385093167702\n",
      "[3]F1score : 0.8574622521640318\n",
      "[3]Precision : 0.8160204624146445\n",
      "[3]Recall : 0.9033385093167702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaemin\\Anaconda3\\envs\\py38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE 적용 전 Train 레이블 값 분포: \n",
      " 0.0    22300\n",
      "1.0     1194\n",
      "2.0      656\n",
      "dtype: int64\n",
      "SMOTE 적용 전 Test 레이블 값 분포: \n",
      " 0.0    2351\n",
      "1.0     150\n",
      "2.0      75\n",
      "dtype: int64\n",
      "SMOTE 적용 후 학습용 피처/레이블 데이터 세트:  (2576, 6) (2576, 1)\n",
      "SMOTE 적용 후 Train 레이블 값 분포: \n",
      " 0.0    22300\n",
      "1.0    22300\n",
      "2.0    22300\n",
      "dtype: int64\n",
      "SMOTE 적용 후 Test 레이블 값 분포: \n",
      " 0.0    2351\n",
      "1.0     150\n",
      "2.0      75\n",
      "dtype: int64\n",
      "X_test 2576\n",
      "y_test tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "[1] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[2] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[3] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[4] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[5] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[6] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[7] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[8] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[9] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[10] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[11] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[12] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[13] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[14] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[15] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[16] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[17] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[18] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[19] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[20] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[21] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[22] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[23] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[24] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[25] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[26] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[27] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[28] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[29] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[30] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[31] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[32] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[33] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[34] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[35] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[36] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[37] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[38] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[39] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[40] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[41] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[42] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[43] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[44] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[45] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[46] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[47] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[48] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[49] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[50] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[51] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[52] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[53] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[54] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[55] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[56] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[57] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[58] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[59] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[60] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[61] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[62] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[63] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[64] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[65] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[66] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[67] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[68] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[69] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[70] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[71] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[72] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[73] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[74] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[75] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[76] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[77] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[78] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[79] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[80] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[81] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[82] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[83] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[84] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[85] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[86] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[87] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[88] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[89] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[90] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[91] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[92] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[93] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[94] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[95] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[96] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[97] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[98] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[99] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[100] Test Loss: 1.0986, Accuracy: 91.27%\n",
      "[4]Accuracy : 91.26552795031056\n",
      "[4]F1score : 0.870977293327299\n",
      "[4]Precision : 0.8329396592048918\n",
      "[4]Recall : 0.9126552795031055\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaemin\\Anaconda3\\envs\\py38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE 적용 전 Train 레이블 값 분포: \n",
      " 0.0    22300\n",
      "1.0     1194\n",
      "2.0      656\n",
      "dtype: int64\n",
      "SMOTE 적용 전 Test 레이블 값 분포: \n",
      " 0.0    2381\n",
      "1.0     127\n",
      "2.0      68\n",
      "dtype: int64\n",
      "SMOTE 적용 후 학습용 피처/레이블 데이터 세트:  (2576, 6) (2576, 1)\n",
      "SMOTE 적용 후 Train 레이블 값 분포: \n",
      " 0.0    22300\n",
      "1.0    22300\n",
      "2.0    22300\n",
      "dtype: int64\n",
      "SMOTE 적용 후 Test 레이블 값 분포: \n",
      " 0.0    2381\n",
      "1.0     127\n",
      "2.0      68\n",
      "dtype: int64\n",
      "X_test 2576\n",
      "y_test tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "[1] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[2] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[3] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[4] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[5] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[6] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[7] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[8] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[9] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[10] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[11] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[12] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[13] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[14] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[15] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[16] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[17] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[18] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[19] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[20] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[21] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[22] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[23] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[24] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[25] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[26] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[27] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[28] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[29] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[30] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[31] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[32] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[33] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[34] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[35] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[36] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[37] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[38] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[39] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[40] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[41] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[42] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[43] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[44] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[45] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[46] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[47] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[48] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[49] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[50] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[51] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[52] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[53] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[54] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[55] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[56] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[57] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[58] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[59] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[60] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[61] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[62] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[63] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[64] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[65] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[66] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[67] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[68] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[69] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[70] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[71] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[72] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[73] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[74] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[75] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[76] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[77] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[78] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[79] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[80] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[81] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[82] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[83] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[84] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[85] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[86] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[87] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[88] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[89] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[90] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[91] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[92] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[93] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[94] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[95] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[96] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[97] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[98] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[99] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[100] Test Loss: 1.0986, Accuracy: 92.43%\n",
      "[5]Accuracy : 92.43012422360249\n",
      "[5]F1score : 0.8879407939334175\n",
      "[5]Precision : 0.8543327863990587\n",
      "[5]Recall : 0.9243012422360248\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaemin\\Anaconda3\\envs\\py38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE 적용 전 Train 레이블 값 분포: \n",
      " 0.0    22300\n",
      "1.0     1194\n",
      "2.0      656\n",
      "dtype: int64\n",
      "SMOTE 적용 전 Test 레이블 값 분포: \n",
      " 0.0    2406\n",
      "1.0     125\n",
      "2.0      45\n",
      "dtype: int64\n",
      "SMOTE 적용 후 학습용 피처/레이블 데이터 세트:  (2576, 6) (2576, 1)\n",
      "SMOTE 적용 후 Train 레이블 값 분포: \n",
      " 0.0    22300\n",
      "1.0    22300\n",
      "2.0    22300\n",
      "dtype: int64\n",
      "SMOTE 적용 후 Test 레이블 값 분포: \n",
      " 0.0    2406\n",
      "1.0     125\n",
      "2.0      45\n",
      "dtype: int64\n",
      "X_test 2576\n",
      "y_test tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "[1] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[2] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[3] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[4] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[5] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[6] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[7] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[8] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[9] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[10] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[11] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[12] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[13] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[14] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[15] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[16] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[17] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[18] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[19] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[20] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[21] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[22] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[23] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[24] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[25] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[26] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[27] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[28] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[29] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[30] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[31] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[32] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[33] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[34] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[35] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[36] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[37] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[38] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[39] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[40] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[41] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[42] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[43] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[44] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[45] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[46] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[47] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[48] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[49] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[50] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[51] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[52] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[53] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[54] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[55] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[56] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[57] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[58] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[59] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[60] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[61] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[62] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[63] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[64] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[65] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[66] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[67] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[68] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[69] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[70] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[71] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[72] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[73] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[74] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[75] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[76] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[77] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[78] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[79] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[80] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[81] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[82] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[83] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[84] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[85] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[86] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[87] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[88] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[89] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[90] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[91] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[92] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[93] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[94] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[95] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[96] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[97] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[98] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[99] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[100] Test Loss: 1.0986, Accuracy: 93.40%\n",
      "[6]Accuracy : 93.40062111801242\n",
      "[6]F1score : 0.9021352645922838\n",
      "[6]Precision : 0.8723676025230508\n",
      "[6]Recall : 0.9340062111801242\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaemin\\Anaconda3\\envs\\py38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE 적용 전 Train 레이블 값 분포: \n",
      " 0.0    22300\n",
      "1.0     1194\n",
      "2.0      656\n",
      "dtype: int64\n",
      "SMOTE 적용 전 Test 레이블 값 분포: \n",
      " 0.0    2432\n",
      "1.0     102\n",
      "2.0      42\n",
      "dtype: int64\n",
      "SMOTE 적용 후 학습용 피처/레이블 데이터 세트:  (2576, 6) (2576, 1)\n",
      "SMOTE 적용 후 Train 레이블 값 분포: \n",
      " 0.0    22300\n",
      "1.0    22300\n",
      "2.0    22300\n",
      "dtype: int64\n",
      "SMOTE 적용 후 Test 레이블 값 분포: \n",
      " 0.0    2432\n",
      "1.0     102\n",
      "2.0      42\n",
      "dtype: int64\n",
      "X_test 2576\n",
      "y_test tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "[1] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[2] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[3] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[4] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[5] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[6] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[7] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[8] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[9] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[10] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[11] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[12] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[13] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[14] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[15] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[16] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[17] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[18] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[19] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[20] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[21] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[22] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[23] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[24] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[25] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[26] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[27] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[28] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[29] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[30] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[31] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[32] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[33] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[34] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[35] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[36] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[37] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[38] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[39] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[40] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[41] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[42] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[43] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[44] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[45] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[46] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[47] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[48] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[49] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[50] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[51] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[52] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[53] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[54] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[55] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[56] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[57] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[58] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[59] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[60] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[61] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[62] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[63] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[64] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[65] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[66] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[67] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[68] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[69] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[70] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[71] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[72] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[73] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[74] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[75] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[76] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[77] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[78] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[79] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[80] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[81] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[82] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[83] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[84] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[85] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[86] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[87] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[88] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[89] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[90] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[91] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[92] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[93] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[94] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[95] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[96] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[97] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[98] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[99] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[100] Test Loss: 1.0986, Accuracy: 94.41%\n",
      "[7]Accuracy : 94.40993788819875\n",
      "[7]F1score : 0.9169527513741987\n",
      "[7]Precision : 0.8913236372053548\n",
      "[7]Recall : 0.9440993788819876\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaemin\\Anaconda3\\envs\\py38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE 적용 전 Train 레이블 값 분포: \n",
      " 0.0    22300\n",
      "1.0     1194\n",
      "2.0      656\n",
      "dtype: int64\n",
      "SMOTE 적용 전 Test 레이블 값 분포: \n",
      " 0.0    2394\n",
      "1.0     126\n",
      "2.0      56\n",
      "dtype: int64\n",
      "SMOTE 적용 후 학습용 피처/레이블 데이터 세트:  (2576, 6) (2576, 1)\n",
      "SMOTE 적용 후 Train 레이블 값 분포: \n",
      " 0.0    22300\n",
      "1.0    22300\n",
      "2.0    22300\n",
      "dtype: int64\n",
      "SMOTE 적용 후 Test 레이블 값 분포: \n",
      " 0.0    2394\n",
      "1.0     126\n",
      "2.0      56\n",
      "dtype: int64\n",
      "X_test 2576\n",
      "y_test tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "[1] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[2] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[3] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[4] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[5] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[6] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[7] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[8] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[9] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[10] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[11] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[12] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[13] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[14] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[15] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[16] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[17] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[18] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[19] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[20] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[21] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[22] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[23] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[24] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[25] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[26] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[27] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[28] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[29] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[30] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[31] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[32] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[33] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[34] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[35] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[36] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[37] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[38] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[39] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[40] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[41] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[42] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[43] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[44] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[45] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[46] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[47] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[48] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[49] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[50] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[51] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[52] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[53] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[54] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[55] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[56] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[57] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[58] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[59] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[60] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[61] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[62] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[63] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[64] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[65] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[66] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[67] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[68] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[69] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[70] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[71] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[72] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[73] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[74] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[75] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[76] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[77] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[78] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[79] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[80] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[81] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[82] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[83] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[84] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[85] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[86] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[87] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[88] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[89] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[90] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[91] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[92] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[93] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[94] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[95] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[96] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[97] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[98] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[99] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[100] Test Loss: 1.0986, Accuracy: 92.93%\n",
      "[8]Accuracy : 92.93478260869566\n",
      "[8]F1score : 0.8953153704837722\n",
      "[8]Precision : 0.863687381852552\n",
      "[8]Recall : 0.9293478260869565\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaemin\\Anaconda3\\envs\\py38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE 적용 전 Train 레이블 값 분포: \n",
      " 0.0    22300\n",
      "1.0     1194\n",
      "2.0      656\n",
      "dtype: int64\n",
      "SMOTE 적용 전 Test 레이블 값 분포: \n",
      " 0.0    2421\n",
      "1.0      82\n",
      "2.0      73\n",
      "dtype: int64\n",
      "SMOTE 적용 후 학습용 피처/레이블 데이터 세트:  (2576, 6) (2576, 1)\n",
      "SMOTE 적용 후 Train 레이블 값 분포: \n",
      " 0.0    22300\n",
      "1.0    22300\n",
      "2.0    22300\n",
      "dtype: int64\n",
      "SMOTE 적용 후 Test 레이블 값 분포: \n",
      " 0.0    2421\n",
      "1.0      82\n",
      "2.0      73\n",
      "dtype: int64\n",
      "X_test 2576\n",
      "y_test tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "[1] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[2] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[3] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[4] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[5] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[6] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[7] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[8] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[9] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[10] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[11] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[12] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[13] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[14] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[15] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[16] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[17] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[18] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[19] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[20] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[21] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[22] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[23] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[24] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[25] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[26] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[27] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[28] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[29] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[30] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[31] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[32] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[33] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[34] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[35] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[36] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[37] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[38] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[39] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[40] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[41] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[42] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[43] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[44] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[45] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[46] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[47] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[48] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[49] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[50] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[51] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[52] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[53] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[54] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[55] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[56] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[57] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[58] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[59] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[60] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[61] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[62] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[63] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[64] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[65] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[66] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[67] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[68] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[69] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[70] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[71] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[72] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[73] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[74] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[75] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[76] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[77] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[78] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[79] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[80] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[81] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[82] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[83] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[84] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[85] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[86] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[87] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[88] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[89] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[90] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[91] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[92] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[93] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[94] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[95] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[96] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[97] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[98] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[99] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[100] Test Loss: 1.0986, Accuracy: 93.98%\n",
      "[9]Accuracy : 93.98291925465838\n",
      "[9]F1score : 0.9106769962598678\n",
      "[9]Precision : 0.8832789111627637\n",
      "[9]Recall : 0.9398291925465838\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaemin\\Anaconda3\\envs\\py38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    model=DNN().to(DEVICE)\n",
    "    # 옵티마이저를 정의합니다. 옵티마이저에는 model.parameters()를 지정해야 합니다.\n",
    "    optimizer    = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    # 손실함수(loss function)을 지정합니다. Multi-Class Classification 이기 때문에 CrossEntropy 손실을 지정하였습니다.\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    X_test=empty\n",
    "    X_train=empty\n",
    "    y_test=empty\n",
    "    y_train=empty\n",
    "    y_test_list=[]\n",
    "    for j in range(322):\n",
    "        X_temp_test=X.iloc[Count_2*j+Count_1*i:Count_2*j+Count_1*(i+1)]\n",
    "        X_test=pd.concat([X_test,X_temp_test])\n",
    "        X_temp_train=X.iloc[Count_2*j+Count_1:Count_2*(j+1)]\n",
    "        X_train=pd.concat([X_train,X_temp_train])\n",
    "        \n",
    "        y_temp_test=y.iloc[Count_2*j+Count_1*i:Count_2*j+Count_1*(i+1)]\n",
    "        y_test=pd.concat([y_test,y_temp_test])\n",
    "        y_temp_train=y.iloc[Count_2*j+Count_1:Count_2*(j+1)]\n",
    "        y_train=pd.concat([y_train,y_temp_train])\n",
    "        \n",
    "    \n",
    "    print('SMOTE 적용 전 Train 레이블 값 분포: \\n', y_train.value_counts())\n",
    "    print('SMOTE 적용 전 Test 레이블 값 분포: \\n', y_test.value_counts())\n",
    "    \n",
    "    # SMOTE 적용\n",
    "    smote = SMOTE(random_state=0)\n",
    "    X_train, y_train = smote.fit_resample(X_train,y_train)\n",
    "#     X_test,y_test = smote.fit_resample(X_test,y_test)\n",
    "    print('SMOTE 적용 후 학습용 피처/레이블 데이터 세트: ', X_test.shape, y_test.shape)\n",
    "    print('SMOTE 적용 후 Train 레이블 값 분포: \\n', y_train.value_counts())\n",
    "    print('SMOTE 적용 후 Test 레이블 값 분포: \\n', y_test.value_counts())\n",
    "\n",
    "    \n",
    "    #모든 데이터 torch로 변환\n",
    "    X_train = torch.FloatTensor(X_train.to_numpy())\n",
    "    X_test = torch.FloatTensor(X_test.to_numpy())    \n",
    "    print(\"X_test\",len(X_test))\n",
    "    y_train=y_train.to_numpy()\n",
    "    y_train=np.ravel(y_train, order='C')\n",
    "    y_train = torch.LongTensor(y_train)\n",
    "    y_test=y_test.to_numpy()\n",
    "    y_test=np.ravel(y_test, order='C')\n",
    "    y_test = torch.LongTensor(y_test)\n",
    "    print(\"y_test\",y_test)\n",
    "    # train_dataset, test_dataset을 구별하여 정의\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    test_dataset=TensorDataset(X_test, y_test)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=16,shuffle=False)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=16,shuffle=False)\n",
    "    \n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        train(model, train_dataloader, optimizer)\n",
    "        test_loss, test_accuracy, predict = evaluate(model, test_dataloader)\n",
    "\n",
    "        print('[{}] Test Loss: {:.4f}, Accuracy: {:.2f}%'.format(epoch, test_loss, test_accuracy))\n",
    "        \n",
    "#     print(\"[{}]Predict : {}\".format(i,predict))\n",
    "    #Accuracy\n",
    "    #test label 데이터 토치에서 list로 변경\n",
    "    y_test_list=y_test.tolist()\n",
    "\n",
    "    accuracy=accuracy_score(y_test_list, predict) * 100\n",
    "    print(\"[{}]Accuracy : {}\".format(i,accuracy))   \n",
    "    #f1score\n",
    "    f1 = f1_score(y_test_list,predict, average='weighted')\n",
    "    print(\"[{}]F1score : {}\".format(i,f1))\n",
    "    #precision/recall\n",
    "    p_rlist=sk(y_test_list,predict,average='weighted')\n",
    "    print(\"[{}]Precision : {}\".format(i,p_rlist[0]))\n",
    "    print(\"[{}]Recall : {}\".format(i,p_rlist[1]))\n",
    "    print()\n",
    "     #결과 배열에 넣기\n",
    "    Result[i][0]=accuracy\n",
    "    Result[i][1]=f1\n",
    "    Result[i][2]=p_rlist[0]\n",
    "    Result[i][3]=p_rlist[1]\n",
    "    del accuracy\n",
    "    del f1\n",
    "    del p_rlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e273ef83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.897516</td>\n",
       "      <td>0.836725</td>\n",
       "      <td>0.790277</td>\n",
       "      <td>0.888975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92.041925</td>\n",
       "      <td>0.882278</td>\n",
       "      <td>0.847172</td>\n",
       "      <td>0.920419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89.091615</td>\n",
       "      <td>0.839521</td>\n",
       "      <td>0.793732</td>\n",
       "      <td>0.890916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.333851</td>\n",
       "      <td>0.857462</td>\n",
       "      <td>0.816020</td>\n",
       "      <td>0.903339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91.265528</td>\n",
       "      <td>0.870977</td>\n",
       "      <td>0.832940</td>\n",
       "      <td>0.912655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>92.430124</td>\n",
       "      <td>0.887941</td>\n",
       "      <td>0.854333</td>\n",
       "      <td>0.924301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>93.400621</td>\n",
       "      <td>0.902135</td>\n",
       "      <td>0.872368</td>\n",
       "      <td>0.934006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>94.409938</td>\n",
       "      <td>0.916953</td>\n",
       "      <td>0.891324</td>\n",
       "      <td>0.944099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>92.934783</td>\n",
       "      <td>0.895315</td>\n",
       "      <td>0.863687</td>\n",
       "      <td>0.929348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>93.982919</td>\n",
       "      <td>0.910677</td>\n",
       "      <td>0.883279</td>\n",
       "      <td>0.939829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy  F1-Score  Precision    Recall\n",
       "0  88.897516  0.836725   0.790277  0.888975\n",
       "1  92.041925  0.882278   0.847172  0.920419\n",
       "2  89.091615  0.839521   0.793732  0.890916\n",
       "3  90.333851  0.857462   0.816020  0.903339\n",
       "4  91.265528  0.870977   0.832940  0.912655\n",
       "5  92.430124  0.887941   0.854333  0.924301\n",
       "6  93.400621  0.902135   0.872368  0.934006\n",
       "7  94.409938  0.916953   0.891324  0.944099\n",
       "8  92.934783  0.895315   0.863687  0.929348\n",
       "9  93.982919  0.910677   0.883279  0.939829"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Result_df=pd.DataFrame(Result,columns=['Accuracy','F1-Score','Precision','Recall'])\n",
    "Result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40b33e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "Matrix=pd.DataFrame(Result_df['Accuracy'],columns=['Accuracy'])\n",
    "Matrix['Accuracy']=Result_df['Accuracy']\n",
    "A=[Result_df['Accuracy'].mean(),Result_df['F1-Score'].mean(),Result_df['Precision'].mean(),Result_df['Recall'].mean()]\n",
    "A=pd.DataFrame(A,columns=['Accuracy'])\n",
    "Matrix=pd.concat([Matrix,A])\n",
    "Matrix=Matrix.transpose()\n",
    "Matrix.to_excel('./PFMatrix2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b76311",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
