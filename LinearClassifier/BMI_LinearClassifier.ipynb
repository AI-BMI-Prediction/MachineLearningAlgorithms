{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d424fe28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]Accuracy : 0.61328125\n",
      "[0]F1score : 0.5989753581971344\n",
      "[0]Precision : 0.5965645032051282\n",
      "[0]Recall : 0.61328125\n",
      "\n",
      "[1]Accuracy : 0.54296875\n",
      "[1]F1score : 0.5274523029102771\n",
      "[1]Precision : 0.5142373077942736\n",
      "[1]Recall : 0.54296875\n",
      "\n",
      "[2]Accuracy : 0.6015625\n",
      "[2]F1score : 0.6270538082172425\n",
      "[2]Precision : 0.6733086768617021\n",
      "[2]Recall : 0.6015625\n",
      "\n",
      "[3]Accuracy : 0.5625\n",
      "[3]F1score : 0.5961257661820867\n",
      "[3]Precision : 0.6919270833333334\n",
      "[3]Recall : 0.5625\n",
      "\n",
      "[4]Accuracy : 0.55859375\n",
      "[4]F1score : 0.562059528543655\n",
      "[4]Precision : 0.5677331327538004\n",
      "[4]Recall : 0.55859375\n",
      "\n",
      "[5]Accuracy : 0.578125\n",
      "[5]F1score : 0.5902564353353741\n",
      "[5]Precision : 0.6112351858782435\n",
      "[5]Recall : 0.578125\n",
      "\n",
      "[6]Accuracy : 0.5859375\n",
      "[6]F1score : 0.6104840540049802\n",
      "[6]Precision : 0.6513290583114802\n",
      "[6]Recall : 0.5859375\n",
      "\n",
      "[7]Accuracy : 0.62109375\n",
      "[7]F1score : 0.6136181980029582\n",
      "[7]Precision : 0.6097467928577918\n",
      "[7]Recall : 0.62109375\n",
      "\n",
      "[8]Accuracy : 0.60546875\n",
      "[8]F1score : 0.6110183037013839\n",
      "[8]Precision : 0.6290672115053886\n",
      "[8]Recall : 0.60546875\n",
      "\n",
      "[9]Accuracy : 0.6171875\n",
      "[9]F1score : 0.6553031185903412\n",
      "[9]Precision : 0.7225457179409994\n",
      "[9]Recall : 0.6171875\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1386: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1386: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1386: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1386: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1386: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1386: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1386: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1386: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1386: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1386: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score ## F1 Score 구하기\n",
    "from sklearn.metrics import precision_recall_fscore_support as sk\n",
    "\n",
    "#먼저 데이터 읽어오기\n",
    "df=pd.read_excel('../optimal_data2/Continous_2weeks_28day_8term.xlsx')\n",
    "df.head()\n",
    "X=df.iloc[:,[1,3,4,5,6,7]]\n",
    "y=df.iloc[:,-1]\n",
    "\n",
    "#스케일링 먼저 하고 ndarray를 dataframe으로 변환\n",
    "scaler = StandardScaler()\n",
    "X=scaler.fit_transform(X)\n",
    "X=pd.DataFrame(X)\n",
    "\n",
    "#결과 넣을 배열\n",
    "Result=[[0 for j in range(4)] for i in range(10)]\n",
    "\n",
    "Count= int(322/10)*8\n",
    "for i in range(10):\n",
    "    #마지막 그룹은 34명\n",
    "    if i==9:\n",
    "        X_test=X.iloc[Count*i:-1]\n",
    "        X_train=X.drop(X.index[Count*i:-1])\n",
    "        y_test=y.iloc[Count*i:-1]\n",
    "        y_train=y.drop(y.index[Count*i:-1])\n",
    "    \n",
    "    #모든 그룹은 32명씩 (마지막은 34)\n",
    "    X_test=X.iloc[Count*i:Count*(i+1)]\n",
    "    X_train=X.drop(X.index[Count*i:Count*(i+1)])\n",
    "    y_test=y.iloc[Count*i:Count*(i+1)]\n",
    "    y_train=y.drop(y.index[Count*i:Count*(i+1)])\n",
    "    \n",
    "    #모델 정의, 예측\n",
    "    model= LogisticRegression(C=1, class_weight='balanced',\n",
    "                          random_state=1, multi_class='ovr',\n",
    "                         n_jobs=-1, solver='lbfgs').fit(X_train,y_train)\n",
    "    \n",
    "    predict=model.predict(X_test)\n",
    "    \n",
    "    #Accuracy\n",
    "    print(\"[{}]Accuracy : {}\".format(i,model.score(X_test,y_test)))\n",
    "    #f1score\n",
    "    f1 = f1_score(y_test,predict,pos_label='positive', average='weighted')\n",
    "    print(\"[{}]F1score : {}\".format(i,f1))\n",
    "    #precision/recall\n",
    "    list=sk(y_test,predict,average='weighted')\n",
    "    print(\"[{}]Precision : {}\".format(i,list[0]))\n",
    "    print(\"[{}]Recall : {}\".format(i,list[1]))\n",
    "    print()\n",
    "    \n",
    "    #결과 배열에 넣기\n",
    "    Result[i][0]=model.score(X_test,y_test)\n",
    "    Result[i][1]=f1\n",
    "    Result[i][2]=list[0]\n",
    "    Result[i][3]=list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "915f0b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Result_df=pd.DataFrame(Result,columns=['Accuracy','F1-Score','Precision','Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77d19539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.613281</td>\n",
       "      <td>0.598975</td>\n",
       "      <td>0.596565</td>\n",
       "      <td>0.613281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.542969</td>\n",
       "      <td>0.527452</td>\n",
       "      <td>0.514237</td>\n",
       "      <td>0.542969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.601562</td>\n",
       "      <td>0.627054</td>\n",
       "      <td>0.673309</td>\n",
       "      <td>0.601562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.596126</td>\n",
       "      <td>0.691927</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.558594</td>\n",
       "      <td>0.562060</td>\n",
       "      <td>0.567733</td>\n",
       "      <td>0.558594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.590256</td>\n",
       "      <td>0.611235</td>\n",
       "      <td>0.578125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.585938</td>\n",
       "      <td>0.610484</td>\n",
       "      <td>0.651329</td>\n",
       "      <td>0.585938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.621094</td>\n",
       "      <td>0.613618</td>\n",
       "      <td>0.609747</td>\n",
       "      <td>0.621094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.605469</td>\n",
       "      <td>0.611018</td>\n",
       "      <td>0.629067</td>\n",
       "      <td>0.605469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.617188</td>\n",
       "      <td>0.655303</td>\n",
       "      <td>0.722546</td>\n",
       "      <td>0.617188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  F1-Score  Precision    Recall\n",
       "0  0.613281  0.598975   0.596565  0.613281\n",
       "1  0.542969  0.527452   0.514237  0.542969\n",
       "2  0.601562  0.627054   0.673309  0.601562\n",
       "3  0.562500  0.596126   0.691927  0.562500\n",
       "4  0.558594  0.562060   0.567733  0.558594\n",
       "5  0.578125  0.590256   0.611235  0.578125\n",
       "6  0.585938  0.610484   0.651329  0.585938\n",
       "7  0.621094  0.613618   0.609747  0.621094\n",
       "8  0.605469  0.611018   0.629067  0.605469\n",
       "9  0.617188  0.655303   0.722546  0.617188"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2218db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average of Accuracy {}\".format())\n",
    "print(\"Average of Accuracy {}\".format())\n",
    "print(\"Average of Accuracy {}\".format())\n",
    "print(\"Average of Accuracy {}\".format())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
