{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cee7f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a57868a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score ## F1 Score 구하기\n",
    "from sklearn.metrics import precision_recall_fscore_support as sk\n",
    "#먼저 데이터 읽어오기\n",
    "df=pd.read_excel('../optimal_data2/Continous_2weeks_2day_1term.xlsx')\n",
    "df.head()\n",
    "X=df.iloc[:,[1,3,4,5,6,7]]\n",
    "y=df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0ca220a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]Accuracy : 0.9145331325301205\n",
      "[0]F1score : 0.8737073663385103\n",
      "[0]Precision : 0.8363708504953549\n",
      "[0]Recall : 0.9145331325301205\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]Accuracy : 0.9036144578313253\n",
      "[1]F1score : 0.8578618270550556\n",
      "[1]Precision : 0.8165190884017999\n",
      "[1]Recall : 0.9036144578313253\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]Accuracy : 0.9446536144578314\n",
      "[2]F1score : 0.9181377963427725\n",
      "[2]Precision : 0.9319047375944456\n",
      "[2]Recall : 0.9446536144578314\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]Accuracy : 0.9435240963855421\n",
      "[3]F1score : 0.9161066972267217\n",
      "[3]Precision : 0.8902377204601539\n",
      "[3]Recall : 0.9435240963855421\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]Accuracy : 0.8524096385542169\n",
      "[4]F1score : 0.792502934898733\n",
      "[4]Precision : 0.7554913937704606\n",
      "[4]Recall : 0.8524096385542169\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]Accuracy : 0.9273343373493976\n",
      "[5]F1score : 0.8923713510027609\n",
      "[5]Precision : 0.8599489732272464\n",
      "[5]Recall : 0.9273343373493976\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]Accuracy : 0.9265813253012049\n",
      "[6]F1score : 0.8919971396354962\n",
      "[6]Precision : 0.8803116573301494\n",
      "[6]Recall : 0.9265813253012049\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]Accuracy : 0.8942018072289156\n",
      "[7]F1score : 0.844257321474329\n",
      "[7]Precision : 0.7995968720514588\n",
      "[7]Recall : 0.8942018072289156\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]Accuracy : 0.9314759036144579\n",
      "[8]F1score : 0.8984293900749197\n",
      "[8]Precision : 0.8676473590143707\n",
      "[8]Recall : 0.9314759036144579\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]Accuracy : 0.9555722891566265\n",
      "[9]F1score : 0.9338630996840654\n",
      "[9]Precision : 0.9131183998040354\n",
      "[9]Recall : 0.9555722891566265\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#스케일링 먼저 하고 ndarray를 dataframe으로 변환\n",
    "scaler = StandardScaler()\n",
    "X=scaler.fit_transform(X)\n",
    "X=pd.DataFrame(X)\n",
    "\n",
    "Result=[[0 for j in range(4)] for i in range(10)]\n",
    "Count= int(322/10)*83\n",
    "for i in range(10):\n",
    "    #마지막 그룹은 34명\n",
    "    if i==9:\n",
    "        X_test=X.iloc[Count*i:-1]\n",
    "        X_train=X.drop(X.index[Count*i:-1])\n",
    "        y_test=y.iloc[Count*i:-1]\n",
    "        y_train=y.drop(y.index[Count*i:-1])\n",
    "    \n",
    "    #모든 그룹은 32명씩gi\n",
    "    X_test=X.iloc[Count*i:Count*(i+1)]\n",
    "    X_train=X.drop(X.index[Count*i:Count*(i+1)])\n",
    "    y_test=y.iloc[Count*i:Count*(i+1)]\n",
    "    y_train=y.drop(y.index[Count*i:Count*(i+1)])\n",
    "    #모델 정의, 예측\n",
    "    model = svm.SVC(kernel='rbf') # rbf Kernel\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    predict=model.predict(X_test)\n",
    "        \n",
    "    #Accuracy\n",
    "    print(\"[{}]Accuracy : {}\".format(i,model.score(X_test,y_test)))\n",
    "\n",
    "    #f1score\n",
    "    f1 = f1_score(y_test,predict, average='weighted')\n",
    "    print(\"[{}]F1score : {}\".format(i,f1))\n",
    "    \n",
    "    #precision/recall\n",
    "    list=sk(y_test,predict,average='weighted')\n",
    "    print(\"[{}]Precision : {}\".format(i,list[0]))\n",
    "    print(\"[{}]Recall : {}\".format(i,list[1]))\n",
    "    print(\"\")\n",
    "\n",
    "    #결과 배열에 넣기\n",
    "    Result[i][0]=model.score(X_test,y_test)\n",
    "    Result[i][1]=f1\n",
    "    Result[i][2]=list[0]\n",
    "    Result[i][3]=list[1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8526528e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.914533</td>\n",
       "      <td>0.873707</td>\n",
       "      <td>0.836371</td>\n",
       "      <td>0.914533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.903614</td>\n",
       "      <td>0.857862</td>\n",
       "      <td>0.816519</td>\n",
       "      <td>0.903614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.944654</td>\n",
       "      <td>0.918138</td>\n",
       "      <td>0.931905</td>\n",
       "      <td>0.944654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.943524</td>\n",
       "      <td>0.916107</td>\n",
       "      <td>0.890238</td>\n",
       "      <td>0.943524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.852410</td>\n",
       "      <td>0.792503</td>\n",
       "      <td>0.755491</td>\n",
       "      <td>0.852410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.927334</td>\n",
       "      <td>0.892371</td>\n",
       "      <td>0.859949</td>\n",
       "      <td>0.927334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.926581</td>\n",
       "      <td>0.891997</td>\n",
       "      <td>0.880312</td>\n",
       "      <td>0.926581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.894202</td>\n",
       "      <td>0.844257</td>\n",
       "      <td>0.799597</td>\n",
       "      <td>0.894202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.931476</td>\n",
       "      <td>0.898429</td>\n",
       "      <td>0.867647</td>\n",
       "      <td>0.931476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.955572</td>\n",
       "      <td>0.933863</td>\n",
       "      <td>0.913118</td>\n",
       "      <td>0.955572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  F1-Score  Precision    Recall\n",
       "0  0.914533  0.873707   0.836371  0.914533\n",
       "1  0.903614  0.857862   0.816519  0.903614\n",
       "2  0.944654  0.918138   0.931905  0.944654\n",
       "3  0.943524  0.916107   0.890238  0.943524\n",
       "4  0.852410  0.792503   0.755491  0.852410\n",
       "5  0.927334  0.892371   0.859949  0.927334\n",
       "6  0.926581  0.891997   0.880312  0.926581\n",
       "7  0.894202  0.844257   0.799597  0.894202\n",
       "8  0.931476  0.898429   0.867647  0.931476\n",
       "9  0.955572  0.933863   0.913118  0.955572"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Result_df=pd.DataFrame(Result,columns=['Accuracy','F1-Score','Precision','Recall'])\n",
    "Result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36393ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of Accuracy 0.9193900602409638\n",
      "Average of F1-Score 0.8819234923733366\n",
      "Average of Precision 0.8551147052149476\n",
      "Average of Recall 0.9193900602409638\n"
     ]
    }
   ],
   "source": [
    "print(\"Average of Accuracy {}\".format(Result_df['Accuracy'].mean()))\n",
    "print(\"Average of F1-Score {}\".format(Result_df['F1-Score'].mean()))\n",
    "print(\"Average of Precision {}\".format(Result_df['Precision'].mean()))\n",
    "print(\"Average of Recall {}\".format(Result_df['Recall'].mean()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
