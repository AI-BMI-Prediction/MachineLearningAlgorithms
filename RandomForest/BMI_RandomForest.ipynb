{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cb176fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score ## F1 Score 구하기\n",
    "from sklearn.metrics import precision_recall_fscore_support as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86457b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#먼저 데이터 읽어오기\n",
    "df=pd.read_excel('../optimal_data2/Continous_2weeks_2day_1term.xlsx')\n",
    "df.head()\n",
    "X=df.iloc[:,[1,3,4,5,6,7]]\n",
    "y=df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c651777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#스케일링 먼저 하고 ndarray를 dataframe으로 변환\n",
    "scaler = StandardScaler()\n",
    "X=scaler.fit_transform(X)\n",
    "X=pd.DataFrame(X)\n",
    "\n",
    "#결과 넣을 배열\n",
    "Result=[[0 for j in range(4)] for i in range(10)]\n",
    "\n",
    "Count= int(322/10)*83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3d54105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]Accuracy : 0.9145331325301205\n",
      "[0]F1score : 0.8737073663385103\n",
      "[0]Precision : 0.8363708504953549\n",
      "[0]Recall : 0.9145331325301205\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1386: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]Accuracy : 0.9036144578313253\n",
      "[1]F1score : 0.8578618270550556\n",
      "[1]Precision : 0.8165190884017999\n",
      "[1]Recall : 0.9036144578313253\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1386: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]Accuracy : 0.9442771084337349\n",
      "[2]F1score : 0.9172141703918697\n",
      "[2]Precision : 0.8916592575119756\n",
      "[2]Recall : 0.9442771084337349\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1386: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]Accuracy : 0.9435240963855421\n",
      "[3]F1score : 0.9161066972267217\n",
      "[3]Precision : 0.8902377204601539\n",
      "[3]Recall : 0.9435240963855421\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1386: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]Accuracy : 0.8561746987951807\n",
      "[4]F1score : 0.7898341846086171\n",
      "[4]Precision : 0.7330351148570184\n",
      "[4]Recall : 0.8561746987951807\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1386: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]Accuracy : 0.9273343373493976\n",
      "[5]F1score : 0.8923713510027609\n",
      "[5]Precision : 0.8599489732272464\n",
      "[5]Recall : 0.9273343373493976\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1386: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]Accuracy : 0.9265813253012049\n",
      "[6]F1score : 0.8912709171648486\n",
      "[6]Precision : 0.8585529523969371\n",
      "[6]Recall : 0.9265813253012049\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1386: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]Accuracy : 0.8942018072289156\n",
      "[7]F1score : 0.844257321474329\n",
      "[7]Precision : 0.7995968720514588\n",
      "[7]Recall : 0.8942018072289156\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1386: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]Accuracy : 0.9314759036144579\n",
      "[8]F1score : 0.8984293900749197\n",
      "[8]Precision : 0.8676473590143707\n",
      "[8]Recall : 0.9314759036144579\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1386: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]Accuracy : 0.9555722891566265\n",
      "[9]F1score : 0.9338630996840654\n",
      "[9]Precision : 0.9131183998040354\n",
      "[9]Recall : 0.9555722891566265\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1386: UserWarning: Note that pos_label (set to 'positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    #마지막 그룹은 34명\n",
    "    if i==9:\n",
    "        X_test=X.iloc[Count*i:-1]\n",
    "        X_train=X.drop(X.index[Count*i:-1])\n",
    "        y_test=y.iloc[Count*i:-1]\n",
    "        y_train=y.drop(y.index[Count*i:-1])\n",
    "    \n",
    "    #모든 그룹은 32명씩 (마지막은 34)\n",
    "    X_test=X.iloc[Count*i:Count*(i+1)]\n",
    "    X_train=X.drop(X.index[Count*i:Count*(i+1)])\n",
    "    y_test=y.iloc[Count*i:Count*(i+1)]\n",
    "    y_train=y.drop(y.index[Count*i:Count*(i+1)])\n",
    "    \n",
    "    #모델 정의, 예측\n",
    "    model= RandomForestClassifier(max_depth=2, random_state=0).fit(X_train,y_train)\n",
    "    \n",
    "    predict=model.predict(X_test)\n",
    "    \n",
    "    #Accuracy\n",
    "    print(\"[{}]Accuracy : {}\".format(i,model.score(X_test,y_test)))\n",
    "    #f1score\n",
    "    f1 = f1_score(y_test,predict,pos_label='positive', average='weighted')\n",
    "    print(\"[{}]F1score : {}\".format(i,f1))\n",
    "    #precision/recall\n",
    "    list=sk(y_test,predict,average='weighted')\n",
    "    print(\"[{}]Precision : {}\".format(i,list[0]))\n",
    "    print(\"[{}]Recall : {}\".format(i,list[1]))\n",
    "    print()\n",
    "    \n",
    "    #결과 배열에 넣기\n",
    "    Result[i][0]=model.score(X_test,y_test)\n",
    "    Result[i][1]=f1\n",
    "    Result[i][2]=list[0]\n",
    "    Result[i][3]=list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c30a5d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Result_df=pd.DataFrame(Result,columns=['Accuracy','F1-Score','Precision','Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6788233d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of Accuracy 0.9197289156626505\n",
      "Average of F1-Score 0.8814916325021699\n",
      "Average of Precision 0.8466686588220351\n",
      "Average of Recall 0.9197289156626505\n"
     ]
    }
   ],
   "source": [
    "print(\"Average of Accuracy {}\".format(Result_df['Accuracy'].mean()))\n",
    "print(\"Average of F1-Score {}\".format(Result_df['F1-Score'].mean()))\n",
    "print(\"Average of Precision {}\".format(Result_df['Precision'].mean()))\n",
    "print(\"Average of Recall {}\".format(Result_df['Recall'].mean()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
